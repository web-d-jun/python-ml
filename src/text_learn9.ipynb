{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, \"'\": 1, ',': 2, '.': 3, '?': 4, 'A': 5, 'B': 6, 'D': 7, 'I': 8, 'M': 9, 'a': 10, 'b': 11, 'c': 12, 'd': 13, 'e': 14, 'f': 15, 'g': 16, 'h': 17, 'i': 18, 'j': 19, 'k': 20, 'l': 21, 'm': 22, 'n': 23, 'o': 24, 'p': 25, 'r': 26, 's': 27, 't': 28, 'u': 29, 'v': 30, 'w': 31, 'y': 32}\n",
      "(426, 10, 33)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "raw_text = '''\n",
    "I get on with life as a programmer,\n",
    "I like to contemplate beer.\n",
    "But when I start to daydream,\n",
    "My mind turns straight to wine.\n",
    "\n",
    "Do I love wine more than beer?\n",
    "\n",
    "I like to use words about beer.\n",
    "But when I stop my talking,\n",
    "My mind turns straight to wine.\n",
    "\n",
    "I hate bugs and errors.\n",
    "But I just think back to wine,\n",
    "And I'm happy once again.\n",
    "\n",
    "I like to hang out with programming and deep learning.\n",
    "But when left alone,\n",
    "My mind turns straight to wine.\n",
    "'''\n",
    "\n",
    "tokens = raw_text.split()\n",
    "raw_text =' '.join(tokens)\n",
    "char_vocab = sorted(list(set(raw_text)))\n",
    "vocab_size = len(char_vocab)\n",
    "\n",
    "char_to_index = dict((char, index) for index,char in enumerate(char_vocab) )\n",
    "print(char_to_index)\n",
    "\n",
    "length = 11\n",
    "sequences = []\n",
    "for i in range(length, len(raw_text)):\n",
    "    seq = raw_text[i - length: i]\n",
    "    sequences.append(seq)\n",
    "\n",
    "sequences[:10]\n",
    "\n",
    "encoded_sequences= []\n",
    "\n",
    "for sequence in sequences:\n",
    "    encoded_sequence = [char_to_index[char] for char in sequence]\n",
    "    encoded_sequences.append(encoded_sequence)\n",
    "\n",
    "encoded_sequences = np.array(encoded_sequences)\n",
    "X_data = encoded_sequences[:, :-1]\n",
    "y_data = encoded_sequences[:, -1]\n",
    "\n",
    "X_data_one_hot = [to_categorical(encoded, num_classes=vocab_size) for encoded in X_data]\n",
    "X_data_one_hot = np.array(X_data_one_hot)\n",
    "y_data_one_hot = to_categorical(y_data, num_classes=vocab_size)\n",
    "print(X_data_one_hot.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b69e231a60>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "hidden_units = 64\n",
    "model = Sequential()\n",
    "model.add(LSTM(hidden_units, input_shape=(X_data_one_hot.shape[1], X_data_one_hot.shape[2])))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_data_one_hot, y_data_one_hot, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I get on wI get on with life as a programmer, I like to use words about beer. But when I stap my yaaa\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def sentence_generation(model, char_to_index, seq_length, seed_text, n):\n",
    "    init_text = seed_text\n",
    "    sentence = ''\n",
    "    for _ in range(n):\n",
    "        encoded = [char_to_index[char] for char in seed_text]\n",
    "        encoded = pad_sequences([encoded], maxlen=seq_length, padding='pre')\n",
    "        encoded = to_categorical(encoded, num_classes=len(char_to_index))\n",
    "\n",
    "        result = model.predict(encoded, verbose=0)\n",
    "        result = np.argmax(result, axis=1)\n",
    "\n",
    "        for char, index in char_to_index.items():\n",
    "            if index == result:\n",
    "                break\n",
    "        \n",
    "        seed_text = seed_text + char\n",
    "        sentence = seed_text + char\n",
    "    \n",
    "    sentence = init_text + sentence\n",
    "    return sentence\n",
    "        \n",
    "\n",
    "print(sentence_generation(model, char_to_index, 10, 'I get on w', 80))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a570dedfbda585c6ec6045193aed6d5d46c787d1787ff4dc0a01ac23261a8ae5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
