{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'말이': 1, '경마장에': 2, '있는': 3, '뛰고': 4, '있다': 5, '그의': 6, '법이다': 7, '가는': 8, '고와야': 9, '오는': 10, '곱다': 11}\n",
      "[2, 3, 1, 4, 5]\n",
      "[]\n",
      "[6, 1, 7]\n",
      "[]\n",
      "[8, 1, 9, 10, 1, 11]\n",
      "[]\n",
      "11\n",
      "학습에 사용되는 샘플 개수: 11\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "text = \"\"\"경마장에 있는 말이 뛰고 있다\\n\n",
    "그의 말이 법이다\\n\n",
    "가는 말이 고와야 오는 말이 곱다\\n\"\"\"\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(tokenizer.word_index)\n",
    "sequences = list()\n",
    "\n",
    "for line in text.split('\\n'):\n",
    "  encoded = tokenizer.texts_to_sequences([line])[0]\n",
    "  print(encoded)\n",
    "\n",
    "  for i in range(1, len(encoded)):\n",
    "    sequence = encoded[:i + 1]\n",
    "    sequences.append(sequence)\n",
    "    \n",
    "print(len(sequences))\n",
    "print('학습에 사용되는 샘플 개수: %d' % len(sequences))\n",
    "\n",
    "max_len = max(len(l) for l in sequences)\n",
    "print(max_len)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
